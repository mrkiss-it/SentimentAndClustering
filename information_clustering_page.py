
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse import hstack, csr_matrix
import joblib

# Import sentiment analysis functions v·ªõi error handling
try:
    from sentiment.sentiment_analysis import *
except ImportError as e:
    st.error(f"‚ùå Kh√¥ng th·ªÉ import sentiment analysis module: {e}")
except Exception as e:
    st.error(f"‚ùå L·ªói khi import: {e}")

def check_wordcloud(data, col_name):
    """T·∫°o WordCloud t·ª´ d·ªØ li·ªáu text"""
    text = " ".join(data)  # G·ªôp danh s√°ch th√†nh chu·ªói
    wc = WordCloud(width=800, height=400, background_color='white').generate(text)

    # T·∫°o figure v√† v·∫Ω WordCloud
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis("off")
    ax.set_title("WordCloud c·ªßa " + col_name, fontsize=16, fontweight='bold', pad=20)

    return fig

def information_clustering_app(choice_lv2_clean, df_reviews):
    """Main function cho Information Clustering app"""
    
    # Load clustering models theo pattern t·ª´ file g·ªëc
    scaler = MinMaxScaler()
    cluster_names = ['EXCELLENT', 'AVERAGE', 'PROBLEMATIC']
    
    try:
        clustering_vectorizer = joblib.load("clustering/tfidf_vectorizer.pkl")
        clustering_model = joblib.load("clustering/best_prediction_model.pkl")
        models_loaded = True
    except FileNotFoundError as e:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file model: {e}")
        st.info("üí° Vui l√≤ng ki·ªÉm tra c√°c file sau c√≥ t·ªìn t·∫°i:")
        st.info("- clustering/tfidf_vectorizer.pkl")
        st.info("- clustering/best_prediction_model.pkl")
        clustering_vectorizer = None
        clustering_model = None
        models_loaded = False
    except Exception as e:
        st.error(f"‚ùå L·ªói khi load models: {e}")
        clustering_vectorizer = None
        clustering_model = None
        models_loaded = False

    if choice_lv2_clean == "Business Objective":
        st.markdown('<h1 class="section-header">üìå M·ª•c ti√™u ph√¢n c·ª•m th√¥ng tin</h1>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="info-card">
                <h3>üéØ Y√™u c·∫ßu</h3>
                <p><strong>Ph√¢n nh√≥m review</strong> theo n·ªôi dung v√† c·∫£m nh·∫≠n ƒë·ªÉ hi·ªÉu r√µ ƒë·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng nh√≥m c√¥ng ty.</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="info-card">
                <h3>üéØ M·ª•c ti√™u</h3>
                <p>M·ªói c√¥ng ty bi·∫øt m√¨nh thu·ªôc c·ª•m n√†o ‚Üí ƒë∆∞a ra <strong>chi·∫øn l∆∞·ª£c c·∫£i thi·ªán</strong> ph√π h·ª£p.</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Cluster v·ªõi m√†u t·ªëi ƒë·∫πp h∆°n
        st.markdown("### üè∑Ô∏è C√°c nh√≥m ph√¢n c·ª•m")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            <div class="metric-card" style="background: linear-gradient(135deg, #065f46 0%, #047857 100%); border-color: #10b981; color: #d1fae5;">
                <h3 style="color: #6ee7b7;">üèÜ EXCELLENT</h3>
                <p>C√¥ng ty xu·∫•t s·∫Øc v·ªõi ƒë√°nh gi√° r·∫•t t√≠ch c·ª±c</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card" style="background: linear-gradient(135deg, #92400e 0%, #b45309 100%); border-color: #f59e0b; color: #fef3c7;">
                <h3 style="color: #fcd34d;">‚öñÔ∏è AVERAGE</h3>
                <p>C√¥ng ty trung b√¨nh, c·∫ßn c·∫£i thi·ªán m·ªôt s·ªë m·∫∑t</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card" style="background: linear-gradient(135deg, #991b1b 0%, #b91c1c 100%); border-color: #dc2626; color: #fecaca;">
                <h3 style="color: #fca5a5;">‚ö†Ô∏è PROBLEMATIC</h3>
                <p>C√¥ng ty c√≥ nhi·ªÅu v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt</p>
            </div>
            """, unsafe_allow_html=True)

    elif choice_lv2_clean == "Build Project":
        st.markdown('<h1 class="section-header">üèóÔ∏è X√¢y d·ª±ng m√¥ h√¨nh ph√¢n c·ª•m</h1>', unsafe_allow_html=True)
        
        # Theo pattern t·ª´ file g·ªëc
        st.markdown("""
        - Thu·∫≠t to√°n ƒë∆∞·ª£c s·ª≠ d·ª•ng: **KMeans** (ƒë√£ ƒë∆∞·ª£c ch·ªçn l√†m model t·ªët nh·∫•t)
        - Qu√° tr√¨nh x·ª≠ l√Ω:
            1. Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n b·∫±ng TF-IDF
            2. Chu·∫©n h√≥a c√°c ƒë·∫∑c tr∆∞ng s·ªë (rating, salary...)
            3. K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng s·ªë v√† vƒÉn b·∫£n
            4. Ph√¢n c·ª•m b·∫±ng KMeans
        """)

        st.write("##### 1. D·ªØ li·ªáu ƒë·∫ßu v√†o")
        st.dataframe(df_reviews[['Company Name', 'reviews_text']].head(3))
        st.dataframe(df_reviews[['Company Name', 'reviews_text']].tail(3))

        st.write("##### 2. Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n")
        st.code("""
        # Qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω bao g·ªìm:
        - L√†m s·∫°ch vƒÉn b·∫£n
        - Ph√¢n ƒëo·∫°n c√¢u (split sentences)
        - X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n
        - Vector h√≥a b·∫±ng TF-IDF
        """)

        st.write("##### 3. X√¢y d·ª±ng m√¥ h√¨nh")
        st.code("""
        # C√°c b∆∞·ªõc ch√≠nh:
        1. Kh·ªüi t·∫°o MinMaxScaler cho c√°c ƒë·∫∑c tr∆∞ng s·ªë
        2. Load TF-IDF vectorizer ƒë√£ ƒë∆∞·ª£c hu·∫•n luy√™n
        3. Load m√¥ h√¨nh KMeans ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
        4. K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng s·ªë v√† vƒÉn b·∫£n
        5. Ph√¢n c·ª•m b·∫±ng KMeans
        """)

        st.write("##### 4. ƒê√°nh gi√° c·ª•m")
        st.markdown("""
        - C√°c c·ª•m ƒë∆∞·ª£c ƒë·∫∑t t√™n: **EXCELLENT**, **AVERAGE**, **PROBLEMATIC**
        - ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c·ª•m b·∫±ng ph∆∞∆°ng ph√°p Silhouette Score
        - Tr·ª±c quan h√≥a b·∫±ng word cloud cho t·ª´ng c·ª•m
        """)

        # Hi·ªÉn th·ªã word cloud m·∫´u
        fig = check_wordcloud(df_reviews['clean_advance_text2'], 'Reviews')
        st.pyplot(fig, use_container_width=True)

        st.write("##### 5. T·ªïng k·∫øt")
        st.success("Model ph√¢n c·ª•m ƒë√£ s·∫µn s√†ng ƒë·ªÉ ph√¢n lo·∫°i c√°c ƒë√°nh gi√° m·ªõi v√†o 3 nh√≥m ch√≠nh!")

    elif choice_lv2_clean == "New Prediction":
        st.markdown('<h1 class="section-header">üÜï Gom nh√≥m ƒë√°nh gi√° m·ªõi</h1>', unsafe_allow_html=True)
        
        if not models_loaded:
            st.error("‚ùå Kh√¥ng th·ªÉ load clustering models. Vui l√≤ng ki·ªÉm tra l·∫°i file models.")
            st.info("üí° C·∫ßn c√°c file sau trong th∆∞ m·ª•c clustering/:")
            st.info("- tfidf_vectorizer.pkl")
            st.info("- best_prediction_model.pkl")
        else:
            st.markdown("""
            - Nh·∫≠p d·ªØ li·ªáu review m·ªõi ‚Üí ƒë∆∞a v√†o m√¥ h√¨nh clustering.
            - M·ªói review/c√¥ng ty ƒë∆∞·ª£c g√°n v√†o 1 c·ª•m ‚Üí gi√∫p hi·ªÉu n·ªôi dung t·ªïng qu√°t.
            """)
            
            text = st.text_area(label="Nh·∫≠p n·ªôi dung c·ªßa b·∫°n:")

            rating = st.slider("Rating", 1, 5, 1)
            salary = st.slider("Salary & benefits", 1, 5, 1)
            training = st.slider("Training & learning", 1, 5, 1)
            cares = st.slider("Management cares about me", 1, 5, 1)
            fun = st.slider("Culture & fun", 1, 5, 1)
            workspace = st.slider("Office & workspace", 1, 5, 1)
            print(rating, salary, training, cares, fun, workspace)

            if text != '':
                try:
                    process_text = process_basic_text(text)
                    lang = detect_lang_safe(process_text)

                    split_txt = split_sentences_by_meaning(process_text, lang)
                    process_advance_text = process_split_text(split_txt, lang)
                    print(process_advance_text)

                    X_tfidf = clustering_vectorizer.transform([process_text])
                    X_num = scaler.fit_transform([[rating, salary, training, cares, fun, workspace]])
                    X = hstack([X_num, X_tfidf])

                    y_pred = clustering_model.predict(X)[0]
                    st.write(f"ƒê√¢y l√† c√¥ng ty: {cluster_names[y_pred]}")

                    fig = check_wordcloud([process_text], 'clean_text')
                    st.pyplot(fig, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"‚ùå C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh ph√¢n t√≠ch: {str(e)}")
                    st.info("üí° Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra l·∫°i n·ªôi dung ƒë·∫ßu v√†o.")