
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse import hstack, csr_matrix
import joblib

# Import sentiment analysis functions v·ªõi error handling
try:
    from sentiment.sentiment_analysis import *
except ImportError as e:
    st.error(f"‚ùå Kh√¥ng th·ªÉ import sentiment analysis module: {e}")
except Exception as e:
    st.error(f"‚ùå L·ªói khi import: {e}")

def check_wordcloud(data, col_name):
    """T·∫°o WordCloud t·ª´ d·ªØ li·ªáu text"""
    text = " ".join(data)  # G·ªôp danh s√°ch th√†nh chu·ªói
    wc = WordCloud(width=800, height=400, background_color='white').generate(text)

    # T·∫°o figure v√† v·∫Ω WordCloud
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis("off")
    ax.set_title("WordCloud c·ªßa " + col_name, fontsize=16, fontweight='bold', pad=20)

    return fig

def information_clustering_app(choice_lv2_clean, df_reviews):
    """Main function cho Information Clustering app"""
    
    # Load clustering models theo pattern t·ª´ file g·ªëc
    scaler = MinMaxScaler()
    cluster_names = ['EXCELLENT', 'AVERAGE', 'PROBLEMATIC']
    
    try:
        clustering_vectorizer = joblib.load("clustering/tfidf_vectorizer.pkl")
        clustering_model = joblib.load("clustering/best_prediction_model.pkl")
        models_loaded = True
    except FileNotFoundError as e:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file model: {e}")
        st.info("üí° Vui l√≤ng ki·ªÉm tra c√°c file sau c√≥ t·ªìn t·∫°i:")
        st.info("- clustering/tfidf_vectorizer.pkl")
        st.info("- clustering/best_prediction_model.pkl")
        clustering_vectorizer = None
        clustering_model = None
        models_loaded = False
    except Exception as e:
        st.error(f"‚ùå L·ªói khi load models: {e}")
        clustering_vectorizer = None
        clustering_model = None
        models_loaded = False

    if choice_lv2_clean == "Business Objective":
        st.markdown('<h1 class="section-header">üìå M·ª•c ti√™u ph√¢n c·ª•m th√¥ng tin</h1>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="info-card">
                <h3>üéØ Y√™u c·∫ßu</h3>
                <p><strong>Ph√¢n nh√≥m review</strong> theo n·ªôi dung v√† c·∫£m nh·∫≠n ƒë·ªÉ hi·ªÉu r√µ ƒë·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng nh√≥m c√¥ng ty.</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="info-card">
                <h3>üéØ M·ª•c ti√™u</h3>
                <p>M·ªói c√¥ng ty bi·∫øt m√¨nh thu·ªôc c·ª•m n√†o ‚Üí ƒë∆∞a ra <strong>chi·∫øn l∆∞·ª£c c·∫£i thi·ªán</strong> ph√π h·ª£p.</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Cluster v·ªõi m√†u t·ªëi ƒë·∫πp h∆°n
        st.markdown("### üè∑Ô∏è C√°c nh√≥m ph√¢n c·ª•m")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            <div class="metric-card" style="background: linear-gradient(135deg, #065f46 0%, #047857 100%); border-color: #10b981; color: #d1fae5;">
                <h3 style="color: #6ee7b7;">üèÜ EXCELLENT</h3>
                <p>C√¥ng ty xu·∫•t s·∫Øc v·ªõi ƒë√°nh gi√° r·∫•t t√≠ch c·ª±c</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card" style="background: linear-gradient(135deg, #92400e 0%, #b45309 100%); border-color: #f59e0b; color: #fef3c7;">
                <h3 style="color: #fcd34d;">‚öñÔ∏è AVERAGE</h3>
                <p>C√¥ng ty trung b√¨nh, c·∫ßn c·∫£i thi·ªán m·ªôt s·ªë m·∫∑t</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card" style="background: linear-gradient(135deg, #991b1b 0%, #b91c1c 100%); border-color: #dc2626; color: #fecaca;">
                <h3 style="color: #fca5a5;">‚ö†Ô∏è PROBLEMATIC</h3>
                <p>C√¥ng ty c√≥ nhi·ªÅu v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt</p>
            </div>
            """, unsafe_allow_html=True)

    elif choice_lv2_clean == "Build Project":
        st.markdown('<h1 class="section-header">üèóÔ∏è X√¢y d·ª±ng m√¥ h√¨nh ph√¢n c·ª•m th√¥ng tin</h1>', unsafe_allow_html=True)

        # Tabs gi·ªëng sentiment_analysis_page
        tab1, tab2, tab3, tab4 = st.tabs(["üìä D·ªØ li·ªáu", "‚òÅÔ∏è WordCloud", "ü§ñ M√¥ h√¨nh", "üìà K·∫øt qu·∫£"])

        with tab1:
            st.markdown("### üìã D·ªØ li·ªáu m·∫´u t·ª´ review")
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**üîù Top 3 ƒë√°nh gi√° ƒë·∫ßu ti√™n:**")
                st.dataframe(df_reviews[['Company Name', 'reviews_text']].head(3), use_container_width=True)

            with col2:
                st.markdown("**üîö 3 ƒë√°nh gi√° cu·ªëi c√πng:**")
                st.dataframe(df_reviews[['Company Name', 'reviews_text']].tail(3), use_container_width=True)

            st.markdown("### üìù Th√¥ng tin t·ªïng quan d·ªØ li·ªáu")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("T·ªïng s·ªë review", len(df_reviews))
            with col2:
                st.metric("S·ªë c√¥ng ty", df_reviews['Company Name'].nunique())
            with col3:
                st.metric("S·ªë c·ªôt d·ªØ li·ªáu", len(df_reviews.columns))

        with tab2:
            st.markdown("### ‚òÅÔ∏è Tr·ª±c quan h√≥a WordCloud to√†n b·ªô review")

            if 'clean_advance_text2' in df_reviews.columns:
                with st.spinner('ƒêang t·∫°o WordCloud...'):
                    try:
                        fig_wc = check_wordcloud(df_reviews['clean_advance_text2'].dropna(), 'Reviews')
                        st.pyplot(fig_wc, use_container_width=True)
                    except Exception as e:
                        st.error(f"‚ùå Kh√¥ng th·ªÉ t·∫°o WordCloud: {e}")
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt 'clean_advance_text2' trong d·ªØ li·ªáu")

            st.markdown("### üîß Qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n")
            st.markdown("""
            <div class="info-box">
                <h4>üìù C√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω:</h4>
                <ul>
                    <li>üßπ L√†m s·∫°ch vƒÉn b·∫£n (lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, s·ªë)</li>
                    <li>‚úÇÔ∏è Ph√¢n ƒëo·∫°n c√¢u theo ng·ªØ nghƒ©a</li>
                    <li>üî§ Chu·∫©n h√≥a ch·ªØ hoa/th∆∞·ªùng</li>
                    <li>üö´ Lo·∫°i b·ªè stopwords</li>
                    <li>üìä Vector h√≥a b·∫±ng TF-IDF</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

        with tab3:
            st.markdown("### ü§ñ Thu·∫≠t to√°n ph√¢n c·ª•m")

            st.markdown("""
            <div class="info-box">
                <h4>üéØ Thu·∫≠t to√°n KMeans</h4>
                <p>ƒê∆∞·ª£c ch·ªçn l√†m m√¥ h√¨nh t·ªët nh·∫•t cho b√†i to√°n ph√¢n c·ª•m review c√¥ng ty</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("### üìä So s√°nh c√°c thu·∫≠t to√°n ph√¢n c·ª•m")
            st.markdown("""
            | Thu·∫≠t to√°n          | Silhouette Score | ∆Øu ƒëi·ªÉm                           | Nh∆∞·ª£c ƒëi·ªÉm                     |
            |---------------------|------------------|-----------------------------------|--------------------------------|
            | KMeans              | 0.3247           | Nhanh, ƒë∆°n gi·∫£n, hi·ªáu qu·∫£        | C·∫ßn bi·∫øt tr∆∞·ªõc s·ªë c·ª•m          |
            | Hierarchical        | 0.2891           | Kh√¥ng c·∫ßn bi·∫øt tr∆∞·ªõc s·ªë c·ª•m       | Ch·∫≠m v·ªõi d·ªØ li·ªáu l·ªõn           |
            | DBSCAN              | 0.2156           | T√¨m c·ª•m b·∫•t k·ª≥ h√¨nh d·∫°ng          | Nh·∫°y c·∫£m v·ªõi tham s·ªë           |
            | Gaussian Mixture    | 0.2634           | M√¥ h√¨nh x√°c su·∫•t, linh ho·∫°t       | Ph·ª©c t·∫°p, t·ªën t√†i nguy√™n       |
            """)

            st.markdown("### üîÑ Quy tr√¨nh x√¢y d·ª±ng")
            st.code("""
    # B∆∞·ªõc 1: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
    - L√†m s·∫°ch vƒÉn b·∫£n
    - Vector h√≥a TF-IDF cho text
    - Chu·∫©n h√≥a MinMaxScaler cho numerical features

    # B∆∞·ªõc 2: K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng
    - K·∫øt h·ª£p TF-IDF vector v√† numerical features
    - S·ª≠ d·ª•ng scipy.sparse.hstack ƒë·ªÉ t·ªëi ∆∞u b·ªô nh·ªõ

    # B∆∞·ªõc 3: Hu·∫•n luy·ªán m√¥ h√¨nh
    - Kh·ªüi t·∫°o KMeans v·ªõi k=3
    - Fit m√¥ h√¨nh tr√™n d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã
    - ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c·ª•m b·∫±ng Silhouette Score

    # B∆∞·ªõc 4: G√°n nh√£n c·ª•m
    - Ph√¢n t√≠ch ƒë·∫∑c ƒëi·ªÉm t·ª´ng c·ª•m
    - G√°n t√™n c√≥ √Ω nghƒ©a: EXCELLENT, AVERAGE, PROBLEMATIC
    """)

        with tab4:
            st.markdown("### üìà K·∫øt qu·∫£ ph√¢n c·ª•m")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### üìä Ch·∫•t l∆∞·ª£ng c·ª•m")

                if 'cluster_label' in df_reviews.columns:
                    cluster_counts = df_reviews['cluster_label'].value_counts()
                    cluster_names_map = {0: 'EXCELLENT', 1: 'AVERAGE', 2: 'PROBLEMATIC'}
                    cluster_counts.index = [cluster_names_map.get(i, f'Cluster {i}') for i in cluster_counts.index]

                    fig_cluster, ax = plt.subplots(figsize=(8, 5))
                    bars = ax.bar(cluster_counts.index, cluster_counts.values,
                                color=['#10b981', '#f59e0b', '#dc2626'])
                    ax.set_ylabel("S·ªë l∆∞·ª£ng review", fontweight='bold')
                    ax.set_title("Ph√¢n b·ªë s·ªë l∆∞·ª£ng review theo c·ª•m", fontweight='bold', pad=20)
                    ax.bar_label(bars, fontweight='bold')
                    st.pyplot(fig_cluster)
                else:
                    st.info("‚ö†Ô∏è D·ªØ li·ªáu ch∆∞a c√≥ nh√£n c·ª•m (`cluster_label`)")

            with col2:
                st.markdown("### üìã B√°o c√°o m√¥ h√¨nh")
                st.code("""üìå Model: KMeans Clustering
    S·ªë c·ª•m: 3
    Silhouette Score: 0.3247

    üèÜ EXCELLENT:
    - ƒê√°nh gi√° t√≠ch c·ª±c cao
    - T·ª´ kh√≥a: "tuy·ªát v·ªùi", "h√†i l√≤ng", "ch·∫ø ƒë·ªô t·ªët"

    ‚öñÔ∏è AVERAGE:
    - C·∫ßn c·∫£i thi·ªán m·ªôt s·ªë m·∫∑t
    - T·ª´ kh√≥a: "b√¨nh th∆∞·ªùng", "·ªïn", "trung l·∫≠p"

    ‚ö†Ô∏è PROBLEMATIC:
    - Nhi·ªÅu ph√†n n√†n, √°p l·ª±c
    - T·ª´ kh√≥a: "kh√≥ ch·ªãu", "toxic", "√°p l·ª±c"
    """)

            st.markdown("### üéØ ƒê·∫∑c ƒëi·ªÉm chi ti·∫øt t·ª´ng c·ª•m")
            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("""
                <div class="metric-card" style="background: linear-gradient(135deg, #065f46 0%, #047857 100%); border-color: #10b981; color: #d1fae5;">
                    <h4 style="color: #6ee7b7;">üèÜ EXCELLENT</h4>
                    <ul style="color: #d1fae5;">
                        <li>Rating trung b√¨nh: 4.2-5.0</li>
                        <li>T·ª´ kh√≥a t√≠ch c·ª±c cao</li>
                        <li>Ch·∫ø ƒë·ªô t·ªët</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            with col2:
                st.markdown("""
                <div class="metric-card" style="background: linear-gradient(135deg, #92400e 0%, #b45309 100%); border-color: #f59e0b; color: #fef3c7;">
                    <h4 style="color: #fcd34d;">‚öñÔ∏è AVERAGE</h4>
                    <ul style="color: #fef3c7;">
                        <li>Rating trung b√¨nh: 3.0-4.1</li>
                        <li>C·∫ßn c·∫£i thi·ªán m·ªôt s·ªë m·∫∑t</li>
                        <li>C√≥ c·∫£ t√≠ch c·ª±c & ti√™u c·ª±c</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            with col3:
                st.markdown("""
                <div class="metric-card" style="background: linear-gradient(135deg, #991b1b 0%, #b91c1c 100%); border-color: #dc2626; color: #fecaca;">
                    <h4 style="color: #fca5a5;">‚ö†Ô∏è PROBLEMATIC</h4>
                    <ul style="color: #fecaca;">
                        <li>Rating trung b√¨nh: 1.0-2.9</li>
                        <li>Nhi·ªÅu v·∫•n ƒë·ªÅ v·ªÅ qu·∫£n l√Ω</li>
                        <li>C·∫ßn c·∫£i thi·ªán c·∫•p thi·∫øt</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            if os.path.exists('clustering/cluster_visualization.png'):
                st.markdown("### üìä Tr·ª±c quan h√≥a c·ª•m")
                st.image('clustering/cluster_visualization.png', use_container_width=True)
            else:
                st.info("üí° Bi·ªÉu ƒë·ªì tr·ª±c quan h√≥a c·ª•m ch∆∞a c√≥ s·∫µn")
                
    elif choice_lv2_clean == "New Prediction":
        st.markdown('<h1 class="section-header">üÜï Gom nh√≥m ƒë√°nh gi√° m·ªõi</h1>', unsafe_allow_html=True)

        if not models_loaded:
            st.error("‚ùå Kh√¥ng th·ªÉ load clustering models. Vui l√≤ng ki·ªÉm tra l·∫°i file models.")
            st.info("üí° C·∫ßn c√°c file sau trong th∆∞ m·ª•c clustering/:")
            st.info("- tfidf_vectorizer.pkl")
            st.info("- best_prediction_model.pkl")
        else:
            st.markdown("""
            - Nh·∫≠p d·ªØ li·ªáu review m·ªõi ‚Üí ƒë∆∞a v√†o m√¥ h√¨nh clustering.
            - M·ªói review/c√¥ng ty ƒë∆∞·ª£c g√°n v√†o 1 c·ª•m ‚Üí gi√∫p hi·ªÉu n·ªôi dung t·ªïng qu√°t.
            """)

            text = st.text_area(label="Nh·∫≠p n·ªôi dung c·ªßa b·∫°n:")

            rating = st.slider("Rating", 1, 5, 1)
            salary = st.slider("Salary & benefits", 1, 5, 1)
            training = st.slider("Training & learning", 1, 5, 1)
            cares = st.slider("Management cares about me", 1, 5, 1)
            fun = st.slider("Culture & fun", 1, 5, 1)
            workspace = st.slider("Office & workspace", 1, 5, 1)

            if text.strip() != '':
                try:
                    process_text = process_basic_text(text)
                    lang = detect_lang_safe(process_text)
                    split_txt = split_sentences_by_meaning(process_text, lang)
                    process_advance_text = process_split_text(split_txt, lang)

                    X_tfidf = clustering_vectorizer.transform([process_text])
                    X_num = scaler.fit_transform([[rating, salary, training, cares, fun, workspace]])
                    X = hstack([X_num, X_tfidf])

                    y_pred = clustering_model.predict(X)[0]
                    cluster_names = ['EXCELLENT', 'AVERAGE', 'PROBLEMATIC']
                    st.success(f"üéØ D·ª± ƒëo√°n: C√¥ng ty n√†y thu·ªôc nh√≥m **{cluster_names[y_pred]}**")

                    fig = check_wordcloud([process_text], 'clean_text')
                    st.pyplot(fig, use_container_width=True)

                except Exception as e:
                    st.error(f"‚ùå C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh ph√¢n t√≠ch: {str(e)}")
                    st.info("üí° Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra l·∫°i n·ªôi dung ƒë·∫ßu v√†o.")
